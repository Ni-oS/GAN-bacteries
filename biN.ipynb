{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44782eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70ea925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = pd.read_csv('20long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36707331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>F1 probability</th>\n",
       "      <th>F2 probability</th>\n",
       "      <th>F3 probability</th>\n",
       "      <th>F4 probability</th>\n",
       "      <th>F5 probability</th>\n",
       "      <th>F6 probability</th>\n",
       "      <th>F7 probability</th>\n",
       "      <th>F8 probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAUACGAGAGGAGGAAGGCAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CACAUAACUGGAGACACAGCAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008088</td>\n",
       "      <td>0.991912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUGUAAUAGGGAGGAGAAGAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UUACUACGUGGAGAAAAGAGAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.983369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UAACAAUCGGAGGCAAUCGUAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGAGAUAGAGGAGGAUUAAAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AGAGAAAGAGGAGGGCAAAGAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AUAUGGUGGAGGAAAUAGUCAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.987325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UGAAUAGGAGGAUUAAGCGAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126444</td>\n",
       "      <td>0.873556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GUAUGAAGAGGAGAAAAGGUAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GUACGAAGAGGAGGAAUAUAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.966258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UAAUGAGUACAUCGAAUCGCAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.999158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GAACAGAGAGGAGAAAAAGAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017355</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.973554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AGAAGAGGAGGACUGAGAUGAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ACAAAGAAUGGAGGUACGUUAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060905</td>\n",
       "      <td>0.939095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GGCUUUGUCUACAUCUUUCAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GAAAGUGAUGAGGCAUAGGUAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UUGGAGAAUAGGAGGAAAAGAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>0.988473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AUAACGAGUGGAGGAAAAGAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022179</td>\n",
       "      <td>0.977821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        seq  F1 probability  F2 probability  F3 probability  \\\n",
       "1   AAUACGAGAGGAGGAAGGCAAUG             0.0             0.0        0.000000   \n",
       "2   CACAUAACUGGAGACACAGCAUG             0.0             0.0        0.000000   \n",
       "3   AUGUAAUAGGGAGGAGAAGAAUG             0.0             0.0        0.000000   \n",
       "4   UUACUACGUGGAGAAAAGAGAUG             0.0             0.0        0.000000   \n",
       "5   UAACAAUCGGAGGCAAUCGUAUG             0.0             0.0        0.000463   \n",
       "6   AGAGAUAGAGGAGGAUUAAAAUG             0.0             0.0        0.000000   \n",
       "7   AGAGAAAGAGGAGGGCAAAGAUG             0.0             0.0        0.000000   \n",
       "8   AUAUGGUGGAGGAAAUAGUCAUG             0.0             0.0        0.000000   \n",
       "9   UGAAUAGGAGGAUUAAGCGAAUG             0.0             0.0        0.000000   \n",
       "10  GUAUGAAGAGGAGAAAAGGUAUG             0.0             0.0        0.000000   \n",
       "11  GUACGAAGAGGAGGAAUAUAAUG             0.0             0.0        0.000000   \n",
       "12  UAAUGAGUACAUCGAAUCGCAUG             0.0             0.0        0.000000   \n",
       "13  GAACAGAGAGGAGAAAAAGAAUG             0.0             0.0        0.000000   \n",
       "14  AGAAGAGGAGGACUGAGAUGAUG             0.0             0.0        0.000000   \n",
       "15  ACAAAGAAUGGAGGUACGUUAUG             0.0             0.0        0.000000   \n",
       "16  GGCUUUGUCUACAUCUUUCAAUG             0.0             0.0        0.000000   \n",
       "17  GAAAGUGAUGAGGCAUAGGUAUG             0.0             0.0        0.000000   \n",
       "18  UUGGAGAAUAGGAGGAAAAGAUG             0.0             0.0        0.000000   \n",
       "19  AUAACGAGUGGAGGAAAAGAAUG             0.0             0.0        0.000000   \n",
       "\n",
       "    F4 probability  F5 probability  F6 probability  F7 probability  \\\n",
       "1         0.000000        0.000000        0.000000        0.000000   \n",
       "2         0.000000        0.000000        0.000000        0.008088   \n",
       "3         0.000000        0.000000        0.000000        0.000000   \n",
       "4         0.000000        0.000000        0.000000        0.016631   \n",
       "5         0.000000        0.000000        0.000000        0.000000   \n",
       "6         0.000606        0.000000        0.000000        0.000000   \n",
       "7         0.000000        0.000000        0.000000        0.000000   \n",
       "8         0.000000        0.000000        0.000000        0.012675   \n",
       "9         0.000000        0.000000        0.000000        0.126444   \n",
       "10        0.000000        0.000000        0.000000        0.000000   \n",
       "11        0.000000        0.000000        0.000000        0.033742   \n",
       "12        0.000000        0.000000        0.000000        0.000842   \n",
       "13        0.000000        0.017355        0.000826        0.008264   \n",
       "14        0.000000        0.000000        0.000873        0.000000   \n",
       "15        0.000000        0.000000        0.000000        0.060905   \n",
       "16        0.000000        0.000000        0.000000        0.000000   \n",
       "17        0.000000        0.000000        0.000000        0.000000   \n",
       "18        0.000000        0.000000        0.000000        0.011527   \n",
       "19        0.000000        0.000000        0.000000        0.022179   \n",
       "\n",
       "    F8 probability  \n",
       "1         1.000000  \n",
       "2         0.991912  \n",
       "3         1.000000  \n",
       "4         0.983369  \n",
       "5         0.999537  \n",
       "6         0.999394  \n",
       "7         1.000000  \n",
       "8         0.987325  \n",
       "9         0.873556  \n",
       "10        1.000000  \n",
       "11        0.966258  \n",
       "12        0.999158  \n",
       "13        0.973554  \n",
       "14        0.999127  \n",
       "15        0.939095  \n",
       "16        1.000000  \n",
       "17        1.000000  \n",
       "18        0.988473  \n",
       "19        0.977821  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e99dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(seq):\n",
    "    \"\"\"\n",
    "    Given a DNA sequence, return its one-hot encoding\n",
    "    \"\"\"\n",
    "    # Make sure seq has only allowed bases\n",
    "    allowed = set(\"ACUGN\")\n",
    "    if not set(seq).issubset(allowed):\n",
    "        invalid = set(seq) - allowed\n",
    "        raise ValueError(f\"Sequence contains chars not in allowed DNA alphabet (ACGTN): {invalid}\")\n",
    "        \n",
    "    # Dictionary returning one-hot encoding for each nucleotide \n",
    "    nuc_d = {'A':[1.0,0.0,0.0,0.0],\n",
    "             'C':[0.0,1.0,0.0,0.0],\n",
    "             'G':[0.0,0.0,1.0,0.0],\n",
    "             'U':[0.0,0.0,0.0,1.0],\n",
    "             'N':[0.0,0.0,0.0,0.0]}\n",
    "    \n",
    "    # Create array from nucleotide sequence\n",
    "    vec=np.array([nuc_d[x] for x in seq])\n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5001d983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encode((prob[\"seq\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c7e06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f87bd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.926016\n",
       "1        1.000000\n",
       "2        0.991912\n",
       "3        1.000000\n",
       "4        0.983369\n",
       "           ...   \n",
       "11687    0.000000\n",
       "11688    0.000000\n",
       "11689    0.000000\n",
       "11690    0.000000\n",
       "11691    0.000000\n",
       "Name: F8 probability, Length: 11692, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[\"F8 probability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaaf104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8970c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_split(df, split_frac=0.8, verbose=False):\n",
    "    '''\n",
    "    Given a df of samples, randomly split indices between\n",
    "    train and test at the desired fraction\n",
    "    '''\n",
    "    cols = df.columns # original columns, use to clean up reindexed cols\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # shuffle indices\n",
    "    idxs = list(range(df.shape[0]))\n",
    "    random.shuffle(idxs)\n",
    "\n",
    "    # split shuffled index list by split_frac\n",
    "    split = int(len(idxs)*split_frac)\n",
    "    train_idxs = idxs[:split]\n",
    "    test_idxs = idxs[split:]\n",
    "    \n",
    "    # split dfs and return\n",
    "    train_df = df[df.index.isin(train_idxs)]\n",
    "    test_df = df[df.index.isin(test_idxs)]\n",
    "        \n",
    "    return train_df[cols], test_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "741aa106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7482, 9)\n",
      "Val: (1871, 9)\n",
      "Test: (2339, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>F1 probability</th>\n",
       "      <th>F2 probability</th>\n",
       "      <th>F3 probability</th>\n",
       "      <th>F4 probability</th>\n",
       "      <th>F5 probability</th>\n",
       "      <th>F6 probability</th>\n",
       "      <th>F7 probability</th>\n",
       "      <th>F8 probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CACAUAACUGGAGACACAGCAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008088</td>\n",
       "      <td>0.991912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUGUAAUAGGGAGGAGAAGAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UUACUACGUGGAGAAAAGAGAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.983369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AGAGAUAGAGGAGGAUUAAAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGAGAAAGAGGAGGGCAAAGAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUAUGGUGGAGGAAAUAGUCAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.987325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UGAAUAGGAGGAUUAAGCGAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126444</td>\n",
       "      <td>0.873556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GUAUGAAGAGGAGAAAAGGUAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GUACGAAGAGGAGGAAUAUAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.966258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GAACAGAGAGGAGAAAAAGAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017355</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.973554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        seq  F1 probability  F2 probability  F3 probability  \\\n",
       "1   CACAUAACUGGAGACACAGCAUG             0.0             0.0             0.0   \n",
       "2   AUGUAAUAGGGAGGAGAAGAAUG             0.0             0.0             0.0   \n",
       "3   UUACUACGUGGAGAAAAGAGAUG             0.0             0.0             0.0   \n",
       "5   AGAGAUAGAGGAGGAUUAAAAUG             0.0             0.0             0.0   \n",
       "6   AGAGAAAGAGGAGGGCAAAGAUG             0.0             0.0             0.0   \n",
       "7   AUAUGGUGGAGGAAAUAGUCAUG             0.0             0.0             0.0   \n",
       "8   UGAAUAGGAGGAUUAAGCGAAUG             0.0             0.0             0.0   \n",
       "9   GUAUGAAGAGGAGAAAAGGUAUG             0.0             0.0             0.0   \n",
       "10  GUACGAAGAGGAGGAAUAUAAUG             0.0             0.0             0.0   \n",
       "11  GAACAGAGAGGAGAAAAAGAAUG             0.0             0.0             0.0   \n",
       "\n",
       "    F4 probability  F5 probability  F6 probability  F7 probability  \\\n",
       "1         0.000000        0.000000        0.000000        0.008088   \n",
       "2         0.000000        0.000000        0.000000        0.000000   \n",
       "3         0.000000        0.000000        0.000000        0.016631   \n",
       "5         0.000606        0.000000        0.000000        0.000000   \n",
       "6         0.000000        0.000000        0.000000        0.000000   \n",
       "7         0.000000        0.000000        0.000000        0.012675   \n",
       "8         0.000000        0.000000        0.000000        0.126444   \n",
       "9         0.000000        0.000000        0.000000        0.000000   \n",
       "10        0.000000        0.000000        0.000000        0.033742   \n",
       "11        0.000000        0.017355        0.000826        0.008264   \n",
       "\n",
       "    F8 probability  \n",
       "1         0.991912  \n",
       "2         1.000000  \n",
       "3         0.983369  \n",
       "5         0.999394  \n",
       "6         1.000000  \n",
       "7         0.987325  \n",
       "8         0.873556  \n",
       "9         1.000000  \n",
       "10        0.966258  \n",
       "11        0.973554  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df, test_df = quick_split(prob)\n",
    "train_df, val_df = quick_split(full_train_df)\n",
    "\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Val:\", val_df.shape)\n",
    "print(\"Test:\", test_df.shape)\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2b6e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11692 entries, 0 to 11691\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   seq             11692 non-null  object \n",
      " 1   F1 probability  11692 non-null  float64\n",
      " 2   F2 probability  11692 non-null  float64\n",
      " 3   F3 probability  11692 non-null  float64\n",
      " 4   F4 probability  11692 non-null  float64\n",
      " 5   F5 probability  11692 non-null  float64\n",
      " 6   F6 probability  11692 non-null  float64\n",
      " 7   F7 probability  11692 non-null  float64\n",
      " 8   F8 probability  11692 non-null  float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 822.2+ KB\n"
     ]
    }
   ],
   "source": [
    "prob.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e05f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDatasetOHE(Dataset):\n",
    "    '''\n",
    "    Dataset for one-hot-encoded sequences\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 seq_col='seq',\n",
    "                 target_col='F3 probability'\n",
    "                ):\n",
    "        # +--------------------+\n",
    "        # | Get the X examples |\n",
    "        # +--------------------+\n",
    "        # extract the DNA from the appropriate column in the df\n",
    "        self.seqs = list(df[seq_col].values)\n",
    "        self.seq_len = len(self.seqs[0])\n",
    "        \n",
    "        # one-hot encode sequences, then stack in a torch tensor\n",
    "        self.ohe_seqs = torch.stack([torch.tensor(one_hot_encode(x)) for x in self.seqs])\n",
    "    \n",
    "        # +------------------+\n",
    "        # | Get the Y labels |\n",
    "        # +------------------+\n",
    "        self.labels = torch.tensor(list(df[target_col].values)).unsqueeze(1)\n",
    "        \n",
    "    def __len__(self): return len(self.seqs)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # Given an index, return a tuple of an X with it's associated Y\n",
    "        # This is called inside DataLoader\n",
    "        seq = self.ohe_seqs[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return seq, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "366ac6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloaders(train_df,\n",
    "                      test_df,\n",
    "                      seq_col='seq',\n",
    "                      target_col='F3 probability',\n",
    "                      batch_size=128,\n",
    "                      shuffle=True\n",
    "                     ):\n",
    "    '''\n",
    "    Given a train and test df with some batch construction\n",
    "    details, put them into custom SeqDatasetOHE() objects. \n",
    "    Give the Datasets to the DataLoaders and return.\n",
    "    '''\n",
    "    \n",
    "    # create Datasets    \n",
    "    train_ds = SeqDatasetOHE(train_df,seq_col=seq_col,target_col=target_col)\n",
    "    test_ds = SeqDatasetOHE(test_df,seq_col=seq_col,target_col=target_col)\n",
    "\n",
    "    # Put DataSets into DataLoaders\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    \n",
    "    return train_dl,test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdb51951",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl = build_dataloaders(train_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65db6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very simple linear model\n",
    "class DNA_Linear(nn.Module):\n",
    "    def __init__(self, seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        # the 4 is for our one-hot encoded vector length 4!\n",
    "        self.lin = nn.Linear(4*seq_len, 1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        # reshape to flatten sequence dimension\n",
    "        xb = xb.view(xb.shape[0],self.seq_len*4)\n",
    "        # Linear wraps up the weights/bias dot product operations\n",
    "        out = self.lin(xb)\n",
    "        return out\n",
    "\n",
    "    \n",
    "# basic CNN model\n",
    "class DNA_CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 seq_len,\n",
    "                 num_filters=32,\n",
    "                 kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.conv_net = nn.Sequential(\n",
    "            # 4 is for the 4 nucleotides\n",
    "            nn.Conv1d(4, num_filters, kernel_size=kernel_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_filters*(seq_len-kernel_size+1), 1)\n",
    "        ) \n",
    "    def forward(self, xb):\n",
    "        # reshape view to batch_size x 4channel x seq_len\n",
    "        # permute to put channel in correct order\n",
    "        xb = xb.permute(0,2,1) \n",
    "        \n",
    "        #print(xb.shape)\n",
    "        out = self.conv_net(xb)\n",
    "        return out\n",
    "    \n",
    "    # __FOOTNOTE 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d778c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +--------------------------------+\n",
    "# | Training and fitting functions |\n",
    "# +--------------------------------+\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None,verbose=False):\n",
    "    '''\n",
    "    Apply loss function to a batch of inputs. If no optimizer\n",
    "    is provided, skip the back prop step.\n",
    "    '''\n",
    "    if verbose:\n",
    "        print('loss batch ****')\n",
    "        print(\"xb shape:\",xb.shape)\n",
    "        print(\"yb shape:\",yb.shape)\n",
    "        print(\"yb shape:\",yb.squeeze(1).shape)\n",
    "        #print(\"yb\",yb)\n",
    "\n",
    "    # get the batch output from the model given your input batch \n",
    "    # ** This is the model's prediction for the y labels! **\n",
    "    xb_out = model(xb.float())\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"model out pre loss\", xb_out.shape)\n",
    "        #print('xb_out', xb_out)\n",
    "        print(\"xb_out:\",xb_out.shape)\n",
    "        print(\"yb:\",yb.shape)\n",
    "        print(\"yb.long:\",yb.long().shape)\n",
    "    \n",
    "    loss = loss_func(xb_out, yb.float()) # for MSE/regression\n",
    "    # __FOOTNOTE 2__\n",
    "    \n",
    "    if opt is not None: # if opt\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "    \n",
    "def train_step(model, train_dl, loss_func, device, opt):\n",
    "    '''\n",
    "    Execute 1 set of batched training within an epoch\n",
    "    '''\n",
    "    # Set model to Training mode\n",
    "    model.train()\n",
    "    tl = [] # train losses\n",
    "    ns = [] # batch sizes, n\n",
    "    \n",
    "    # loop through train DataLoader\n",
    "    for xb, yb in train_dl:\n",
    "        # put on GPU\n",
    "        xb, yb = xb.to(device),yb.to(device)\n",
    "        \n",
    "        # provide opt so backprop happens\n",
    "        t, n = loss_batch(model, loss_func, xb, yb, opt=opt)\n",
    "        \n",
    "        # collect train loss and batch sizes\n",
    "        tl.append(t)\n",
    "        ns.append(n)\n",
    "    \n",
    "    # average the losses over all batches    \n",
    "    train_loss = np.sum(np.multiply(tl, ns)) / np.sum(ns)\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "def val_step(model, val_dl, loss_func, device):\n",
    "    '''\n",
    "    Execute 1 set of batched validation within an epoch\n",
    "    '''\n",
    "    # Set model to Evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        vl = [] # val losses\n",
    "        ns = [] # batch sizes, n\n",
    "        \n",
    "        # loop through validation DataLoader\n",
    "        for xb, yb in val_dl:\n",
    "            # put on GPU\n",
    "            xb, yb = xb.to(device),yb.to(device)\n",
    "\n",
    "            # Do NOT provide opt here, so backprop does not happen\n",
    "            v, n = loss_batch(model, loss_func, xb, yb)\n",
    "\n",
    "            # collect val loss and batch sizes\n",
    "            vl.append(v)\n",
    "            ns.append(n)\n",
    "\n",
    "    # average the losses over all batches\n",
    "    val_loss = np.sum(np.multiply(vl, ns)) / np.sum(ns)\n",
    "    \n",
    "    return val_loss\n",
    "    \n",
    "def fit(epochs, model, loss_func, opt, train_dl, val_dl,device,patience=1000):\n",
    "    '''\n",
    "    Fit the model params to the training data, eval on unseen data.\n",
    "    Loop for a number of epochs and keep train of train and val losses \n",
    "    along the way\n",
    "    '''\n",
    "    # keep track of losses\n",
    "    train_losses = []    \n",
    "    val_losses = []\n",
    "    \n",
    "    # loop through epochs\n",
    "    for epoch in range(epochs):\n",
    "        # take a training step\n",
    "        train_loss = train_step(model,train_dl,loss_func,device,opt)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # take a validation step\n",
    "        val_loss = val_step(model,val_dl,loss_func,device)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f\"E{epoch} | train loss: {train_loss:.3f} | val loss: {val_loss:.3f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "def run_model(train_dl,val_dl,model,device,\n",
    "              lr=0.01, epochs=50, \n",
    "              lossf=None,opt=None\n",
    "             ):\n",
    "    '''\n",
    "    Given train and val DataLoaders and a NN model, fit the mode to the training\n",
    "    data. By default, use MSE loss and an SGD optimizer\n",
    "    '''\n",
    "    # define optimizer\n",
    "    if opt:\n",
    "        optimizer = opt\n",
    "    else: # if no opt provided, just use SGD\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    # define loss function\n",
    "    if lossf:\n",
    "        loss_func = lossf\n",
    "    else: # if no loss function provided, just use MSE\n",
    "        loss_func = torch.nn.MSELoss()\n",
    "    \n",
    "    # run the training loop\n",
    "    train_losses, val_losses = fit(\n",
    "                                epochs, \n",
    "                                model, \n",
    "                                loss_func, \n",
    "                                optimizer, \n",
    "                                train_dl, \n",
    "                                val_dl, \n",
    "                                device)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "748a846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0 | train loss: 0.189 | val loss: 0.179\n",
      "E1 | train loss: 0.167 | val loss: 0.166\n",
      "E2 | train loss: 0.157 | val loss: 0.160\n",
      "E3 | train loss: 0.152 | val loss: 0.156\n",
      "E4 | train loss: 0.149 | val loss: 0.154\n",
      "E5 | train loss: 0.147 | val loss: 0.152\n",
      "E6 | train loss: 0.146 | val loss: 0.151\n",
      "E7 | train loss: 0.146 | val loss: 0.151\n",
      "E8 | train loss: 0.145 | val loss: 0.151\n",
      "E9 | train loss: 0.145 | val loss: 0.151\n",
      "E10 | train loss: 0.145 | val loss: 0.150\n",
      "E11 | train loss: 0.144 | val loss: 0.150\n",
      "E12 | train loss: 0.144 | val loss: 0.150\n",
      "E13 | train loss: 0.144 | val loss: 0.150\n",
      "E14 | train loss: 0.144 | val loss: 0.150\n",
      "E15 | train loss: 0.144 | val loss: 0.150\n",
      "E16 | train loss: 0.144 | val loss: 0.151\n",
      "E17 | train loss: 0.144 | val loss: 0.150\n",
      "E18 | train loss: 0.144 | val loss: 0.150\n",
      "E19 | train loss: 0.144 | val loss: 0.150\n",
      "E20 | train loss: 0.144 | val loss: 0.150\n",
      "E21 | train loss: 0.144 | val loss: 0.150\n",
      "E22 | train loss: 0.144 | val loss: 0.151\n",
      "E23 | train loss: 0.144 | val loss: 0.150\n",
      "E24 | train loss: 0.144 | val loss: 0.150\n",
      "E25 | train loss: 0.144 | val loss: 0.150\n",
      "E26 | train loss: 0.144 | val loss: 0.150\n",
      "E27 | train loss: 0.144 | val loss: 0.150\n",
      "E28 | train loss: 0.144 | val loss: 0.150\n",
      "E29 | train loss: 0.144 | val loss: 0.150\n",
      "E30 | train loss: 0.144 | val loss: 0.150\n",
      "E31 | train loss: 0.144 | val loss: 0.150\n",
      "E32 | train loss: 0.144 | val loss: 0.150\n",
      "E33 | train loss: 0.144 | val loss: 0.150\n",
      "E34 | train loss: 0.144 | val loss: 0.150\n",
      "E35 | train loss: 0.144 | val loss: 0.150\n",
      "E36 | train loss: 0.144 | val loss: 0.150\n",
      "E37 | train loss: 0.144 | val loss: 0.150\n",
      "E38 | train loss: 0.144 | val loss: 0.150\n",
      "E39 | train loss: 0.144 | val loss: 0.150\n",
      "E40 | train loss: 0.144 | val loss: 0.150\n",
      "E41 | train loss: 0.144 | val loss: 0.150\n",
      "E42 | train loss: 0.144 | val loss: 0.151\n",
      "E43 | train loss: 0.144 | val loss: 0.150\n",
      "E44 | train loss: 0.144 | val loss: 0.150\n",
      "E45 | train loss: 0.144 | val loss: 0.150\n",
      "E46 | train loss: 0.144 | val loss: 0.150\n",
      "E47 | train loss: 0.144 | val loss: 0.150\n",
      "E48 | train loss: 0.144 | val loss: 0.151\n",
      "E49 | train loss: 0.144 | val loss: 0.150\n"
     ]
    }
   ],
   "source": [
    "# get the sequence length from the first seq in the df\n",
    "seq_len = len(train_df['seq'].values[0])\n",
    "\n",
    "# create Linear model object\n",
    "model_lin = DNA_Linear(seq_len)\n",
    "model_lin.to(DEVICE) # put on GPU\n",
    "\n",
    "# run the model with default settings!\n",
    "lin_train_losses, lin_val_losses = run_model(\n",
    "    train_dl, \n",
    "    val_dl, \n",
    "    model_lin,\n",
    "    DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f621280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_loss_plot(data_label_list,loss_type=\"MSE Loss\",sparse_n=0):\n",
    "    '''\n",
    "    For each train/test loss trajectory, plot loss by epoch\n",
    "    '''\n",
    "    for i,(train_data,test_data,label) in enumerate(data_label_list):    \n",
    "        plt.plot(train_data,linestyle='--',color=f\"C{i}\", label=f\"{label} Train\")\n",
    "        plt.plot(test_data,color=f\"C{i}\", label=f\"{label} Val\",linewidth=3.0)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylabel(loss_type)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(bbox_to_anchor=(1,1),loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3421d6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lin_data_label = (lin_train_losses,lin_val_losses,\"Lin\")\n",
    "quick_loss_plot([lin_data_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abbe712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0 | train loss: 0.151 | val loss: 0.157\n",
      "E1 | train loss: 0.148 | val loss: 0.155\n",
      "E2 | train loss: 0.147 | val loss: 0.154\n",
      "E3 | train loss: 0.146 | val loss: 0.153\n",
      "E4 | train loss: 0.145 | val loss: 0.153\n",
      "E5 | train loss: 0.145 | val loss: 0.152\n",
      "E6 | train loss: 0.144 | val loss: 0.151\n",
      "E7 | train loss: 0.144 | val loss: 0.151\n",
      "E8 | train loss: 0.144 | val loss: 0.151\n",
      "E9 | train loss: 0.144 | val loss: 0.152\n",
      "E10 | train loss: 0.143 | val loss: 0.152\n",
      "E11 | train loss: 0.143 | val loss: 0.151\n",
      "E12 | train loss: 0.143 | val loss: 0.151\n",
      "E13 | train loss: 0.143 | val loss: 0.150\n",
      "E14 | train loss: 0.143 | val loss: 0.150\n",
      "E15 | train loss: 0.143 | val loss: 0.150\n",
      "E16 | train loss: 0.142 | val loss: 0.151\n",
      "E17 | train loss: 0.143 | val loss: 0.150\n",
      "E18 | train loss: 0.142 | val loss: 0.150\n",
      "E19 | train loss: 0.142 | val loss: 0.150\n",
      "E20 | train loss: 0.142 | val loss: 0.150\n",
      "E21 | train loss: 0.142 | val loss: 0.150\n",
      "E22 | train loss: 0.142 | val loss: 0.150\n",
      "E23 | train loss: 0.141 | val loss: 0.150\n",
      "E24 | train loss: 0.142 | val loss: 0.150\n",
      "E25 | train loss: 0.141 | val loss: 0.153\n",
      "E26 | train loss: 0.142 | val loss: 0.150\n",
      "E27 | train loss: 0.141 | val loss: 0.150\n",
      "E28 | train loss: 0.141 | val loss: 0.152\n",
      "E29 | train loss: 0.141 | val loss: 0.150\n",
      "E30 | train loss: 0.141 | val loss: 0.150\n",
      "E31 | train loss: 0.141 | val loss: 0.150\n",
      "E32 | train loss: 0.141 | val loss: 0.151\n",
      "E33 | train loss: 0.141 | val loss: 0.150\n",
      "E34 | train loss: 0.141 | val loss: 0.151\n",
      "E35 | train loss: 0.141 | val loss: 0.150\n",
      "E36 | train loss: 0.141 | val loss: 0.150\n",
      "E37 | train loss: 0.141 | val loss: 0.150\n",
      "E38 | train loss: 0.140 | val loss: 0.150\n",
      "E39 | train loss: 0.140 | val loss: 0.150\n",
      "E40 | train loss: 0.140 | val loss: 0.153\n",
      "E41 | train loss: 0.140 | val loss: 0.150\n",
      "E42 | train loss: 0.140 | val loss: 0.151\n",
      "E43 | train loss: 0.140 | val loss: 0.151\n",
      "E44 | train loss: 0.140 | val loss: 0.150\n",
      "E45 | train loss: 0.140 | val loss: 0.150\n",
      "E46 | train loss: 0.140 | val loss: 0.151\n",
      "E47 | train loss: 0.140 | val loss: 0.150\n",
      "E48 | train loss: 0.140 | val loss: 0.150\n",
      "E49 | train loss: 0.140 | val loss: 0.150\n"
     ]
    }
   ],
   "source": [
    "seq_len = len(train_df['seq'].values[0])\n",
    "\n",
    "# create Linear model object\n",
    "model_cnn = DNA_CNN(seq_len)\n",
    "model_cnn.to(DEVICE) # put on GPU\n",
    "\n",
    "# run the model with default settings!\n",
    "cnn_train_losses, cnn_val_losses = run_model(\n",
    "    train_dl, \n",
    "    val_dl, \n",
    "    model_cnn,\n",
    "    DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a640cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_data_label = (cnn_train_losses,cnn_val_losses,\"CNN\")\n",
    "quick_loss_plot([lin_data_label,cnn_data_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8e39990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = dict(test_df[['seq','F3 probability']].values)\n",
    "\n",
    "def quick_seq_pred(model, seqs, oracle):\n",
    "    '''\n",
    "    Given a model and some sequences, get the model's predictions\n",
    "    for those sequences and compare to the oracle (true) output\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame(data = {'seq': [], 'pred': [], 'actual': [], \"diff\": []})\n",
    "    for dna in seqs:\n",
    "        s = torch.tensor(one_hot_encode(dna)).unsqueeze(0).to(DEVICE)\n",
    "        pred = model(s.float())\n",
    "        actual = oracle[dna]\n",
    "        diff = pred.item() - actual\n",
    "        #print(f\"{dna}: pred:{pred.item():.3f} actual:{actual:.3f} ({diff:.3f})\")\n",
    "        #df2 = pd.DataFrame(data = {'seq': [dna], 'pred': [pred.item()], 'actual': [actual]})\n",
    "        df = df.append({'seq': dna, 'pred': pred.item(), 'actual': actual, \"diff\": diff}, ignore_index = True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def quick_8mer_pred(model, oracle):\n",
    "\n",
    "    for seqs in oracle.keys():\n",
    "        quick_seq_pred(model, oracle, oracle)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "598827aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = quick_seq_pred(model_lin, oracle.keys(), oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9fdbfaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAUACGAGAGGAGGAAGGCAAUG</td>\n",
       "      <td>0.066782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UAAUGAGUACAUCGAAUCGCAUG</td>\n",
       "      <td>0.269617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GGCUUUGUCUACAUCUUUCAAUG</td>\n",
       "      <td>0.225467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUGAGACGGGAGUAAAUAACAUG</td>\n",
       "      <td>0.159584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGAGAGAGGAGAGAGAAAAAAUG</td>\n",
       "      <td>0.092565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AGUUACAGAGGAGAACGAGCAUG</td>\n",
       "      <td>0.086097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GUAAUGACGGUAAUCUCGUAAUG</td>\n",
       "      <td>0.173785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAAAGAACAGGAGGAACCUUAUG</td>\n",
       "      <td>0.103517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAAAAACGGGAGGAAAGUAAAUG</td>\n",
       "      <td>0.094527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AUAUGUAGGAGAGAAAAAAUAUG</td>\n",
       "      <td>0.120179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GAAUACAGAGGAGAAUGAGUAUG</td>\n",
       "      <td>0.124846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ACAUAGAUGAGGAAAAAGAUAUG</td>\n",
       "      <td>0.096451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ACAUAGAUAGGAGAAAAUGAAUG</td>\n",
       "      <td>0.083723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GUUAAACGAGAGGAGGAAACAUG</td>\n",
       "      <td>0.151402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ACUCGAAAGGAGGUAAGAAUAUG</td>\n",
       "      <td>0.119729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CAACUGAGAAGAGGAAAAUUAUG</td>\n",
       "      <td>0.125053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AAACAGAGUAGGAGAAAGAGAUG</td>\n",
       "      <td>0.081540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ACAAAAUGUGGAGGAAACGUAUG</td>\n",
       "      <td>0.070223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AAAGAAAGAGGAGAGUCCCGAUG</td>\n",
       "      <td>0.044037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AUUAAGUAGGAGGAAAAUGAAUG</td>\n",
       "      <td>0.128433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        seq      pred  actual      diff\n",
       "0   AAUACGAGAGGAGGAAGGCAAUG  0.066782     0.0  0.066782\n",
       "1   UAAUGAGUACAUCGAAUCGCAUG  0.269617     0.0  0.269617\n",
       "2   GGCUUUGUCUACAUCUUUCAAUG  0.225467     0.0  0.225467\n",
       "3   AUGAGACGGGAGUAAAUAACAUG  0.159584     0.0  0.159584\n",
       "4   AGAGAGAGGAGAGAGAAAAAAUG  0.092565     0.0  0.092565\n",
       "5   AGUUACAGAGGAGAACGAGCAUG  0.086097     0.0  0.086097\n",
       "6   GUAAUGACGGUAAUCUCGUAAUG  0.173785     0.0  0.173785\n",
       "7   CAAAGAACAGGAGGAACCUUAUG  0.103517     0.0  0.103517\n",
       "8   AAAAAACGGGAGGAAAGUAAAUG  0.094527     0.0  0.094527\n",
       "9   AUAUGUAGGAGAGAAAAAAUAUG  0.120179     0.0  0.120179\n",
       "10  GAAUACAGAGGAGAAUGAGUAUG  0.124846     0.0  0.124846\n",
       "11  ACAUAGAUGAGGAAAAAGAUAUG  0.096451     0.0  0.096451\n",
       "12  ACAUAGAUAGGAGAAAAUGAAUG  0.083723     0.0  0.083723\n",
       "13  GUUAAACGAGAGGAGGAAACAUG  0.151402     0.0  0.151402\n",
       "14  ACUCGAAAGGAGGUAAGAAUAUG  0.119729     0.0  0.119729\n",
       "15  CAACUGAGAAGAGGAAAAUUAUG  0.125053     0.0  0.125053\n",
       "16  AAACAGAGUAGGAGAAAGAGAUG  0.081540     0.0  0.081540\n",
       "17  ACAAAAUGUGGAGGAAACGUAUG  0.070223     0.0  0.070223\n",
       "18  AAAGAAAGAGGAGAGUCCCGAUG  0.044037     0.0  0.044037\n",
       "19  AUUAAGUAGGAGGAAAAUGAAUG  0.128433     0.0  0.128433"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "549f1fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>UCGAUCCCUGGAGGUAAAUGAUG</td>\n",
       "      <td>0.093571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>UUAACUACCGGGAGGGCAGGAUG</td>\n",
       "      <td>0.042662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>UUUCAAUACGGAGAAUUCAAAUG</td>\n",
       "      <td>0.174346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>AUAAGACCGGCCAACACGUUAUG</td>\n",
       "      <td>0.083420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>AUCUCGGCAUUACACGACAUAUG</td>\n",
       "      <td>0.240268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>CAAAUACUACACGGCUGAGCAUG</td>\n",
       "      <td>0.143736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>AAACAAAAGUAAAUGGGAUUAUG</td>\n",
       "      <td>0.250463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>AGGGUAAGUCGCUAAUAGUAAUG</td>\n",
       "      <td>0.145499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>AUCUUUGGUAUGUUACUAGCAUG</td>\n",
       "      <td>0.199058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>GAACAAAGUACACAAACACGAUG</td>\n",
       "      <td>0.166138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>GAUGUGGAUUUUUACACAAUAUG</td>\n",
       "      <td>0.322586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>UGACUCAGAUACAACACGCGAUG</td>\n",
       "      <td>0.126326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>AUUAUCGACCAACGAAUAAGAUG</td>\n",
       "      <td>0.251413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.748587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>GUGAAGAGGUAUAGAGAAGGAUG</td>\n",
       "      <td>0.233341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.766659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>UAAUCAGAAUAAGUAGAAUAAUG</td>\n",
       "      <td>0.309823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.690177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>UAUUCAAUUAGAAAGAGAACAUG</td>\n",
       "      <td>0.197756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.802244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>UAGUGGAUGAGUAAAGGCAUAUG</td>\n",
       "      <td>0.216178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>UUCAAGCCACAGGAGCAUGAAUG</td>\n",
       "      <td>0.201368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>GACAUAGAAAGAGAACAAGAAUG</td>\n",
       "      <td>0.182351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>AUUCAUGGGUGAGAAAAUAUAUG</td>\n",
       "      <td>0.125434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seq      pred  actual      diff\n",
       "2319  UCGAUCCCUGGAGGUAAAUGAUG  0.093571     0.0  0.093571\n",
       "2320  UUAACUACCGGGAGGGCAGGAUG  0.042662     0.0  0.042662\n",
       "2321  UUUCAAUACGGAGAAUUCAAAUG  0.174346     0.0  0.174346\n",
       "2322  AUAAGACCGGCCAACACGUUAUG  0.083420     0.0  0.083420\n",
       "2323  AUCUCGGCAUUACACGACAUAUG  0.240268     0.0  0.240268\n",
       "2324  CAAAUACUACACGGCUGAGCAUG  0.143736     0.0  0.143736\n",
       "2325  AAACAAAAGUAAAUGGGAUUAUG  0.250463     0.0  0.250463\n",
       "2326  AGGGUAAGUCGCUAAUAGUAAUG  0.145499     0.0  0.145499\n",
       "2327  AUCUUUGGUAUGUUACUAGCAUG  0.199058     0.0  0.199058\n",
       "2328  GAACAAAGUACACAAACACGAUG  0.166138     0.0  0.166138\n",
       "2329  GAUGUGGAUUUUUACACAAUAUG  0.322586     0.0  0.322586\n",
       "2330  UGACUCAGAUACAACACGCGAUG  0.126326     0.0  0.126326\n",
       "2331  AUUAUCGACCAACGAAUAAGAUG  0.251413     1.0 -0.748587\n",
       "2332  GUGAAGAGGUAUAGAGAAGGAUG  0.233341     1.0 -0.766659\n",
       "2333  UAAUCAGAAUAAGUAGAAUAAUG  0.309823     1.0 -0.690177\n",
       "2334  UAUUCAAUUAGAAAGAGAACAUG  0.197756     1.0 -0.802244\n",
       "2335  UAGUGGAUGAGUAAAGGCAUAUG  0.216178     0.0  0.216178\n",
       "2336  UUCAAGCCACAGGAGCAUGAAUG  0.201368     0.0  0.201368\n",
       "2337  GACAUAGAAAGAGAACAAGAAUG  0.182351     0.0  0.182351\n",
       "2338  AUUCAUGGGUGAGAAAAUAUAUG  0.125434     0.0  0.125434"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496018a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
