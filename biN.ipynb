{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44782eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ec51519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "input = torch.tensor([[3.2, 1.3,0.2, 0.8]],dtype=torch.float)\n",
    "target = torch.tensor([0], dtype=torch.long)\n",
    "criterion(input, target)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ea925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = pd.read_csv('20long.csv')\n",
    "prob[\"binary\"] = prob[\"F3 probability\"].round()\n",
    "prob.binary = prob.binary.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36707331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>F1 probability</th>\n",
       "      <th>F2 probability</th>\n",
       "      <th>F3 probability</th>\n",
       "      <th>F4 probability</th>\n",
       "      <th>F5 probability</th>\n",
       "      <th>F6 probability</th>\n",
       "      <th>F7 probability</th>\n",
       "      <th>F8 probability</th>\n",
       "      <th>binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [seq, F1 probability, F2 probability, F3 probability, F4 probability, F5 probability, F6 probability, F7 probability, F8 probability, binary]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[(prob[\"F3 probability\"] < 0) | (prob[\"F3 probability\"] > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e99dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(seq):\n",
    "    \"\"\"\n",
    "    Given a DNA sequence, return its one-hot encoding\n",
    "    \"\"\"\n",
    "    # Make sure seq has only allowed bases\n",
    "    allowed = set(\"ACUGN\")\n",
    "    if not set(seq).issubset(allowed):\n",
    "        invalid = set(seq) - allowed\n",
    "        raise ValueError(f\"Sequence contains chars not in allowed DNA alphabet (ACGTN): {invalid}\")\n",
    "        \n",
    "    # Dictionary returning one-hot encoding for each nucleotide \n",
    "    nuc_d = {'A':[1.0,0.0,0.0,0.0],\n",
    "             'C':[0.0,1.0,0.0,0.0],\n",
    "             'G':[0.0,0.0,1.0,0.0],\n",
    "             'U':[0.0,0.0,0.0,1.0],\n",
    "             'N':[0.0,0.0,0.0,0.0]}\n",
    "    \n",
    "    # Create array from nucleotide sequence\n",
    "    vec=np.array([nuc_d[x] for x in seq])\n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5001d983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encode((prob[\"seq\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0c7e06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaaf104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8970c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_split(df, split_frac=0.8, verbose=False):\n",
    "    '''\n",
    "    Given a df of samples, randomly split indices between\n",
    "    train and test at the desired fraction\n",
    "    '''\n",
    "    cols = df.columns # original columns, use to clean up reindexed cols\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # shuffle indices\n",
    "    idxs = list(range(df.shape[0]))\n",
    "    random.shuffle(idxs)\n",
    "\n",
    "    # split shuffled index list by split_frac\n",
    "    split = int(len(idxs)*split_frac)\n",
    "    train_idxs = idxs[:split]\n",
    "    test_idxs = idxs[split:]\n",
    "    \n",
    "    # split dfs and return\n",
    "    train_df = df[df.index.isin(train_idxs)]\n",
    "    test_df = df[df.index.isin(test_idxs)]\n",
    "        \n",
    "    return train_df[cols], test_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "741aa106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7482, 10)\n",
      "Val: (1871, 10)\n",
      "Test: (2339, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>F1 probability</th>\n",
       "      <th>F2 probability</th>\n",
       "      <th>F3 probability</th>\n",
       "      <th>F4 probability</th>\n",
       "      <th>F5 probability</th>\n",
       "      <th>F6 probability</th>\n",
       "      <th>F7 probability</th>\n",
       "      <th>F8 probability</th>\n",
       "      <th>binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAUACGAGAGGAGGAAGGCAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CACAUAACUGGAGACACAGCAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008088</td>\n",
       "      <td>0.991912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUGUAAUAGGGAGGAGAAGAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UUACUACGUGGAGAAAAGAGAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.983369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UAACAAUCGGAGGCAAUCGUAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AGAGAUAGAGGAGGAUUAAAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGAGAAAGAGGAGGGCAAAGAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUAUGGUGGAGGAAAUAGUCAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.987325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UGAAUAGGAGGAUUAAGCGAAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126444</td>\n",
       "      <td>0.873556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GUAUGAAGAGGAGAAAAGGUAUG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       seq  F1 probability  F2 probability  F3 probability  \\\n",
       "0  AAUACGAGAGGAGGAAGGCAAUG             0.0             0.0        0.000000   \n",
       "1  CACAUAACUGGAGACACAGCAUG             0.0             0.0        0.000000   \n",
       "2  AUGUAAUAGGGAGGAGAAGAAUG             0.0             0.0        0.000000   \n",
       "3  UUACUACGUGGAGAAAAGAGAUG             0.0             0.0        0.000000   \n",
       "4  UAACAAUCGGAGGCAAUCGUAUG             0.0             0.0        0.000463   \n",
       "5  AGAGAUAGAGGAGGAUUAAAAUG             0.0             0.0        0.000000   \n",
       "6  AGAGAAAGAGGAGGGCAAAGAUG             0.0             0.0        0.000000   \n",
       "7  AUAUGGUGGAGGAAAUAGUCAUG             0.0             0.0        0.000000   \n",
       "8  UGAAUAGGAGGAUUAAGCGAAUG             0.0             0.0        0.000000   \n",
       "9  GUAUGAAGAGGAGAAAAGGUAUG             0.0             0.0        0.000000   \n",
       "\n",
       "   F4 probability  F5 probability  F6 probability  F7 probability  \\\n",
       "0        0.000000             0.0             0.0        0.000000   \n",
       "1        0.000000             0.0             0.0        0.008088   \n",
       "2        0.000000             0.0             0.0        0.000000   \n",
       "3        0.000000             0.0             0.0        0.016631   \n",
       "4        0.000000             0.0             0.0        0.000000   \n",
       "5        0.000606             0.0             0.0        0.000000   \n",
       "6        0.000000             0.0             0.0        0.000000   \n",
       "7        0.000000             0.0             0.0        0.012675   \n",
       "8        0.000000             0.0             0.0        0.126444   \n",
       "9        0.000000             0.0             0.0        0.000000   \n",
       "\n",
       "   F8 probability  binary  \n",
       "0        1.000000       0  \n",
       "1        0.991912       0  \n",
       "2        1.000000       0  \n",
       "3        0.983369       0  \n",
       "4        0.999537       0  \n",
       "5        0.999394       0  \n",
       "6        1.000000       0  \n",
       "7        0.987325       0  \n",
       "8        0.873556       0  \n",
       "9        1.000000       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df, test_df = quick_split(prob)\n",
    "train_df, val_df = quick_split(full_train_df)\n",
    "\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Val:\", val_df.shape)\n",
    "print(\"Test:\", test_df.shape)\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2b6e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11692 entries, 0 to 11691\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   seq             11692 non-null  object \n",
      " 1   F1 probability  11692 non-null  float64\n",
      " 2   F2 probability  11692 non-null  float64\n",
      " 3   F3 probability  11692 non-null  float64\n",
      " 4   F4 probability  11692 non-null  float64\n",
      " 5   F5 probability  11692 non-null  float64\n",
      " 6   F6 probability  11692 non-null  float64\n",
      " 7   F7 probability  11692 non-null  float64\n",
      " 8   F8 probability  11692 non-null  float64\n",
      " 9   binary          11692 non-null  int32  \n",
      "dtypes: float64(8), int32(1), object(1)\n",
      "memory usage: 867.9+ KB\n"
     ]
    }
   ],
   "source": [
    "prob.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87e05f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDatasetOHE(Dataset):\n",
    "    '''\n",
    "    Dataset for one-hot-encoded sequences\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 seq_col='seq',\n",
    "                 target_col='F3 probability'\n",
    "                ):\n",
    "        # +--------------------+\n",
    "        # | Get the X examples |\n",
    "        # +--------------------+\n",
    "        # extract the DNA from the appropriate column in the df\n",
    "        self.seqs = list(df[seq_col].values)\n",
    "        self.seq_len = len(self.seqs[0])\n",
    "        \n",
    "        # one-hot encode sequences, then stack in a torch tensor\n",
    "        self.ohe_seqs = torch.stack([torch.tensor(one_hot_encode(x)) for x in self.seqs])\n",
    "    \n",
    "        # +------------------+\n",
    "        # | Get the Y labels |\n",
    "        # +------------------+\n",
    "        self.labels = torch.tensor(list(df[target_col].values)).unsqueeze(1)\n",
    "        \n",
    "    def __len__(self): return len(self.seqs)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # Given an index, return a tuple of an X with it's associated Y\n",
    "        # This is called inside DataLoader\n",
    "        seq = self.ohe_seqs[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return seq, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "366ac6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloaders(train_df,\n",
    "                      test_df,\n",
    "                      seq_col='seq',\n",
    "                      target_col='F3 probability',\n",
    "                      batch_size=128,\n",
    "                      shuffle=True\n",
    "                     ):\n",
    "    '''\n",
    "    Given a train and test df with some batch construction\n",
    "    details, put them into custom SeqDatasetOHE() objects. \n",
    "    Give the Datasets to the DataLoaders and return.\n",
    "    '''\n",
    "    \n",
    "    # create Datasets    \n",
    "    train_ds = SeqDatasetOHE(train_df,seq_col=seq_col,target_col=target_col)\n",
    "    test_ds = SeqDatasetOHE(test_df,seq_col=seq_col,target_col=target_col)\n",
    "\n",
    "    # Put DataSets into DataLoaders\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    \n",
    "    return train_dl,test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdb51951",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl = build_dataloaders(train_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65db6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very simple linear model\n",
    "class DNA_Linear(nn.Module):\n",
    "    def __init__(self, seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        # the 4 is for our one-hot encoded vector length 4!\n",
    "        self.lin = nn.Linear(4*seq_len, 1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        # reshape to flatten sequence dimension\n",
    "        xb = xb.view(xb.shape[0],self.seq_len*4)\n",
    "        # Linear wraps up the weights/bias dot product operations\n",
    "        out = self.lin(xb)\n",
    "        return out\n",
    "\n",
    "    \n",
    "# basic CNN model\n",
    "class DNA_CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 seq_len,\n",
    "                 num_filters=32,\n",
    "                 kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.conv_net = nn.Sequential(\n",
    "            # 4 is for the 4 nucleotides\n",
    "            nn.Conv1d(4, num_filters, kernel_size=kernel_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_filters*(seq_len-kernel_size+1), 1)\n",
    "        ) \n",
    "    def forward(self, xb):\n",
    "        # reshape view to batch_size x 4channel x seq_len\n",
    "        # permute to put channel in correct order\n",
    "        xb = xb.permute(0,2,1) \n",
    "        \n",
    "        #print(xb.shape)\n",
    "        out = self.conv_net(xb)\n",
    "        return out\n",
    "    \n",
    "    # __FOOTNOTE 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d778c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +--------------------------------+\n",
    "# | Training and fitting functions |\n",
    "# +--------------------------------+\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None,verbose=False):\n",
    "    '''\n",
    "    Apply loss function to a batch of inputs. If no optimizer\n",
    "    is provided, skip the back prop step.\n",
    "    '''\n",
    "    if verbose:\n",
    "        print('loss batch ****')\n",
    "        print(\"xb shape:\",xb.shape)\n",
    "        print(\"yb shape:\",yb.shape)\n",
    "        print(\"yb shape:\",yb.squeeze(1).shape)\n",
    "        #print(\"yb\",yb)\n",
    "\n",
    "    # get the batch output from the model given your input batch \n",
    "    # ** This is the model's prediction for the y labels! **\n",
    "    xb_out = model(xb.float())\n",
    "    if verbose:\n",
    "        print(\"model out pre loss\", xb_out.shape)\n",
    "        #print('xb_out', xb_out)\n",
    "        print(\"xb_out.shape:\",xb_out.shape)\n",
    "        print(\"xb_out.squeeze(0):\",xb_out.squeeze(0).shape)\n",
    "        print(\"yb.squeeze(1).shape\",yb.squeeze(1).shape)\n",
    "        print(\"yb:\",yb.shape)\n",
    "        print(\"yb.long:\",yb.long().shape)\n",
    "        #print(yb)\n",
    "        print(\"yb.long.squeeze(1):\",yb.long().squeeze(1).shape)\n",
    "        print()\n",
    "        print(yb.long().dtype)\n",
    "        #sample_tensor=sample_tensor.type(torch.FloatTensor) \n",
    "        \n",
    "        \n",
    "    yb_long = yb.long().squeeze(1)\n",
    "    m = torch.nn.Sigmoid()\n",
    "    #loss = loss_func(xb_out, yb.float()) # for MSE/regression\n",
    "    # __FOOTNOTE 2__\n",
    "    loss = loss_func(xb_out, yb.float()) # for BCE/classification\n",
    "    \"\"\"staclOverflow разъяснение для размеров и типа входных данных для кросс энтропии\n",
    "    https://stackoverflow.com/questions/53455780/pytorch-lstm-target-dimension-in-calculating-cross-entropy-loss/53458159#53458159\n",
    "    BCE вместо кросс энтропии https://discuss.pytorch.org/t/crossentropy-in-pytorch-getting-target-1-out-of-bounds/71575\n",
    "    \n",
    "    \"\"\"\n",
    "    if opt is not None: # if opt\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "    \n",
    "def train_step(model, train_dl, loss_func, device, opt):\n",
    "    '''\n",
    "    Execute 1 set of batched training within an epoch\n",
    "    '''\n",
    "    # Set model to Training mode\n",
    "    model.train()\n",
    "    tl = [] # train losses\n",
    "    ns = [] # batch sizes, n\n",
    "    \n",
    "    # loop through train DataLoader\n",
    "    for xb, yb in train_dl:\n",
    "        # put on GPU\n",
    "        xb, yb = xb.to(device),yb.to(device)\n",
    "        \n",
    "        # provide opt so backprop happens\n",
    "        t, n = loss_batch(model, loss_func, xb, yb, opt=opt,verbose = False)\n",
    "        \n",
    "        # collect train loss and batch sizes\n",
    "        tl.append(t)\n",
    "        ns.append(n)\n",
    "    \n",
    "    # average the losses over all batches    \n",
    "    train_loss = np.sum(np.multiply(tl, ns)) / np.sum(ns)\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "def val_step(model, val_dl, loss_func, device):\n",
    "    '''\n",
    "    Execute 1 set of batched validation within an epoch\n",
    "    '''\n",
    "    # Set model to Evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        vl = [] # val losses\n",
    "        ns = [] # batch sizes, n\n",
    "        \n",
    "        # loop through validation DataLoader\n",
    "        for xb, yb in val_dl:\n",
    "            # put on GPU\n",
    "            xb, yb = xb.to(device),yb.to(device)\n",
    "\n",
    "            # Do NOT provide opt here, so backprop does not happen\n",
    "            v, n = loss_batch(model, loss_func, xb, yb,verbose =False)\n",
    "\n",
    "            # collect val loss and batch sizes\n",
    "            vl.append(v)\n",
    "            ns.append(n)\n",
    "\n",
    "    # average the losses over all batches\n",
    "    val_loss = np.sum(np.multiply(vl, ns)) / np.sum(ns)\n",
    "    \n",
    "    return val_loss\n",
    "    \n",
    "def fit(epochs, model, loss_func, opt, train_dl, val_dl,device,patience=1000):\n",
    "    '''\n",
    "    Fit the model params to the training data, eval on unseen data.\n",
    "    Loop for a number of epochs and keep train of train and val losses \n",
    "    along the way\n",
    "    '''\n",
    "    # keep track of losses\n",
    "    train_losses = []    \n",
    "    val_losses = []\n",
    "    \n",
    "    # loop through epochs\n",
    "    for epoch in range(epochs):\n",
    "        # take a training step\n",
    "        train_loss = train_step(model,train_dl,loss_func,device,opt)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # take a validation step\n",
    "        val_loss = val_step(model,val_dl,loss_func,device)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f\"E{epoch} | train loss: {train_loss:.3f} | val loss: {val_loss:.3f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "def run_model(train_dl,val_dl,model,device,\n",
    "              lr=0.01, epochs=50, \n",
    "              lossf=None,opt=None\n",
    "             ):\n",
    "    '''\n",
    "    Given train and val DataLoaders and a NN model, fit the mode to the training\n",
    "    data. By default, use MSE loss and an SGD optimizer\n",
    "    '''\n",
    "    # define optimizer\n",
    "    if opt:\n",
    "        optimizer = opt\n",
    "    else: # if no opt provided, just use SGD\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    # define loss function\n",
    "    if lossf:\n",
    "        loss_func = lossf\n",
    "    else: # if no loss function provided, just use MSE\n",
    "        loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # run the training loop\n",
    "    train_losses, val_losses = fit(\n",
    "                                epochs, \n",
    "                                model, \n",
    "                                loss_func, \n",
    "                                optimizer, \n",
    "                                train_dl, \n",
    "                                val_dl, \n",
    "                                device)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "748a846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0 | train loss: 0.555 | val loss: 0.495\n",
      "E1 | train loss: 0.488 | val loss: 0.479\n",
      "E2 | train loss: 0.480 | val loss: 0.477\n",
      "E3 | train loss: 0.479 | val loss: 0.476\n",
      "E4 | train loss: 0.478 | val loss: 0.476\n",
      "E5 | train loss: 0.477 | val loss: 0.475\n",
      "E6 | train loss: 0.476 | val loss: 0.475\n",
      "E7 | train loss: 0.476 | val loss: 0.474\n",
      "E8 | train loss: 0.475 | val loss: 0.474\n",
      "E9 | train loss: 0.474 | val loss: 0.473\n",
      "E10 | train loss: 0.474 | val loss: 0.473\n",
      "E11 | train loss: 0.473 | val loss: 0.473\n",
      "E12 | train loss: 0.473 | val loss: 0.472\n",
      "E13 | train loss: 0.472 | val loss: 0.472\n",
      "E14 | train loss: 0.472 | val loss: 0.472\n",
      "E15 | train loss: 0.471 | val loss: 0.471\n",
      "E16 | train loss: 0.471 | val loss: 0.471\n",
      "E17 | train loss: 0.471 | val loss: 0.471\n",
      "E18 | train loss: 0.470 | val loss: 0.471\n",
      "E19 | train loss: 0.470 | val loss: 0.470\n",
      "E20 | train loss: 0.470 | val loss: 0.470\n",
      "E21 | train loss: 0.469 | val loss: 0.470\n",
      "E22 | train loss: 0.469 | val loss: 0.470\n",
      "E23 | train loss: 0.469 | val loss: 0.470\n",
      "E24 | train loss: 0.468 | val loss: 0.470\n",
      "E25 | train loss: 0.468 | val loss: 0.469\n",
      "E26 | train loss: 0.468 | val loss: 0.469\n",
      "E27 | train loss: 0.468 | val loss: 0.469\n",
      "E28 | train loss: 0.467 | val loss: 0.469\n",
      "E29 | train loss: 0.467 | val loss: 0.469\n",
      "E30 | train loss: 0.467 | val loss: 0.469\n",
      "E31 | train loss: 0.467 | val loss: 0.469\n",
      "E32 | train loss: 0.467 | val loss: 0.469\n",
      "E33 | train loss: 0.466 | val loss: 0.469\n",
      "E34 | train loss: 0.466 | val loss: 0.468\n",
      "E35 | train loss: 0.466 | val loss: 0.468\n",
      "E36 | train loss: 0.466 | val loss: 0.468\n",
      "E37 | train loss: 0.466 | val loss: 0.468\n",
      "E38 | train loss: 0.465 | val loss: 0.468\n",
      "E39 | train loss: 0.465 | val loss: 0.468\n",
      "E40 | train loss: 0.465 | val loss: 0.468\n",
      "E41 | train loss: 0.465 | val loss: 0.468\n",
      "E42 | train loss: 0.465 | val loss: 0.468\n",
      "E43 | train loss: 0.465 | val loss: 0.468\n",
      "E44 | train loss: 0.465 | val loss: 0.468\n",
      "E45 | train loss: 0.465 | val loss: 0.468\n",
      "E46 | train loss: 0.464 | val loss: 0.468\n",
      "E47 | train loss: 0.464 | val loss: 0.468\n",
      "E48 | train loss: 0.464 | val loss: 0.468\n",
      "E49 | train loss: 0.464 | val loss: 0.468\n"
     ]
    }
   ],
   "source": [
    "# get the sequence length from the first seq in the df\n",
    "seq_len = len(train_df['seq'].values[0])\n",
    "\n",
    "# create Linear model object\n",
    "model_lin = DNA_Linear(seq_len)\n",
    "model_lin.to(DEVICE) # put on GPU\n",
    "\n",
    "# run the model with default settings!\n",
    "lin_train_losses, lin_val_losses = run_model(\n",
    "    train_dl, \n",
    "    val_dl, \n",
    "    model_lin,\n",
    "    DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1f621280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_loss_plot(data_label_list,loss_type=\"BCE Loss\",sparse_n=0):\n",
    "    '''\n",
    "    For each train/test loss trajectory, plot loss by epoch\n",
    "    '''\n",
    "    for i,(train_data,test_data,label) in enumerate(data_label_list):    \n",
    "        plt.plot(train_data,linestyle='--',color=f\"C{i}\", label=f\"{label} Train\")\n",
    "        plt.plot(test_data,color=f\"C{i}\", label=f\"{label} Val\",linewidth=3.0)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylabel(loss_type)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(bbox_to_anchor=(1,1),loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3421d6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lin_data_label = (lin_train_losses,lin_val_losses,\"Lin\")\n",
    "quick_loss_plot([lin_data_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "abbe712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0 | train loss: 0.513 | val loss: 0.481\n",
      "E1 | train loss: 0.478 | val loss: 0.481\n",
      "E2 | train loss: 0.478 | val loss: 0.480\n",
      "E3 | train loss: 0.477 | val loss: 0.479\n",
      "E4 | train loss: 0.476 | val loss: 0.479\n",
      "E5 | train loss: 0.475 | val loss: 0.478\n",
      "E6 | train loss: 0.475 | val loss: 0.478\n",
      "E7 | train loss: 0.474 | val loss: 0.477\n",
      "E8 | train loss: 0.473 | val loss: 0.477\n",
      "E9 | train loss: 0.473 | val loss: 0.476\n",
      "E10 | train loss: 0.472 | val loss: 0.475\n",
      "E11 | train loss: 0.472 | val loss: 0.475\n",
      "E12 | train loss: 0.471 | val loss: 0.475\n",
      "E13 | train loss: 0.471 | val loss: 0.474\n",
      "E14 | train loss: 0.470 | val loss: 0.474\n",
      "E15 | train loss: 0.470 | val loss: 0.473\n",
      "E16 | train loss: 0.469 | val loss: 0.473\n",
      "E17 | train loss: 0.469 | val loss: 0.473\n",
      "E18 | train loss: 0.468 | val loss: 0.472\n",
      "E19 | train loss: 0.468 | val loss: 0.472\n",
      "E20 | train loss: 0.467 | val loss: 0.472\n",
      "E21 | train loss: 0.467 | val loss: 0.471\n",
      "E22 | train loss: 0.467 | val loss: 0.471\n",
      "E23 | train loss: 0.466 | val loss: 0.471\n",
      "E24 | train loss: 0.466 | val loss: 0.470\n",
      "E25 | train loss: 0.465 | val loss: 0.471\n",
      "E26 | train loss: 0.465 | val loss: 0.470\n",
      "E27 | train loss: 0.465 | val loss: 0.470\n",
      "E28 | train loss: 0.465 | val loss: 0.470\n",
      "E29 | train loss: 0.464 | val loss: 0.469\n",
      "E30 | train loss: 0.464 | val loss: 0.469\n",
      "E31 | train loss: 0.464 | val loss: 0.469\n",
      "E32 | train loss: 0.463 | val loss: 0.469\n",
      "E33 | train loss: 0.463 | val loss: 0.468\n",
      "E34 | train loss: 0.463 | val loss: 0.468\n",
      "E35 | train loss: 0.463 | val loss: 0.468\n",
      "E36 | train loss: 0.462 | val loss: 0.468\n",
      "E37 | train loss: 0.462 | val loss: 0.468\n",
      "E38 | train loss: 0.462 | val loss: 0.467\n",
      "E39 | train loss: 0.462 | val loss: 0.468\n",
      "E40 | train loss: 0.462 | val loss: 0.467\n",
      "E41 | train loss: 0.461 | val loss: 0.467\n",
      "E42 | train loss: 0.461 | val loss: 0.467\n",
      "E43 | train loss: 0.461 | val loss: 0.467\n",
      "E44 | train loss: 0.461 | val loss: 0.467\n",
      "E45 | train loss: 0.461 | val loss: 0.467\n",
      "E46 | train loss: 0.461 | val loss: 0.466\n",
      "E47 | train loss: 0.460 | val loss: 0.466\n",
      "E48 | train loss: 0.460 | val loss: 0.466\n",
      "E49 | train loss: 0.460 | val loss: 0.466\n"
     ]
    }
   ],
   "source": [
    "seq_len = len(train_df['seq'].values[0])\n",
    "\n",
    "# create Linear model object\n",
    "model_cnn = DNA_CNN(seq_len)\n",
    "model_cnn.to(DEVICE) # put on GPU\n",
    "\n",
    "# run the model with default settings!\n",
    "cnn_train_losses, cnn_val_losses = run_model(\n",
    "    train_dl, \n",
    "    val_dl, \n",
    "    model_cnn,\n",
    "    DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8a640cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_data_label = (cnn_train_losses,cnn_val_losses,\"CNN\")\n",
    "quick_loss_plot([lin_data_label,cnn_data_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8e39990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = dict(test_df[['seq','F3 probability']].values)\n",
    "\n",
    "def quick_seq_pred(model, seqs, oracle):\n",
    "    '''\n",
    "    Given a model and some sequences, get the model's predictions\n",
    "    for those sequences and compare to the oracle (true) output\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame(data = {'seq': [], 'pred': [], 'actual': [], \"diff\": []})\n",
    "    for dna in seqs:\n",
    "        s = torch.tensor(one_hot_encode(dna)).unsqueeze(0).to(DEVICE)\n",
    "        pred = model(s.float())\n",
    "        actual = oracle[dna]\n",
    "        diff = pred.item() - actual\n",
    "        #print(f\"{dna}: pred:{pred.item():.3f} actual:{actual:.3f} ({diff:.3f})\")\n",
    "        #df2 = pd.DataFrame(data = {'seq': [dna], 'pred': [pred.item()], 'actual': [actual]})\n",
    "        df = df.append({'seq': dna, 'pred': pred.item(), 'actual': actual, \"diff\": diff}, ignore_index = True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def quick_8mer_pred(model, oracle):\n",
    "\n",
    "    for seqs in oracle.keys():\n",
    "        quick_seq_pred(model, oracle, oracle)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "598827aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = quick_seq_pred(model_lin, oracle.keys(), oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9fdbfaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UGAAUUAGGAGGGUAUAGAAAUG</td>\n",
       "      <td>-2.018470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.018470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GUACGAAGAGGAGGAAUAUAAUG</td>\n",
       "      <td>-2.104053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.104053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGAAGAGGAGGACUGAGAUGAUG</td>\n",
       "      <td>-2.026808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.026808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UUGGAGAAUAGGAGGAAAAGAUG</td>\n",
       "      <td>-1.472379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.472379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACGAGAAGAGGAGGAGAAAAAUG</td>\n",
       "      <td>-1.884343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.884343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUAGAAGCGGAGGAAUAAUCAUG</td>\n",
       "      <td>-1.577263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.577263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GUGAGUAGAGGAGAUAUAUAAUG</td>\n",
       "      <td>-1.920333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.920333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AGAGAGAGGAGAGAGAAAAAAUG</td>\n",
       "      <td>-1.835910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.835910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AUACGAGAGAGGAUAAUGAGAUG</td>\n",
       "      <td>-1.957115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.957115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAACUGAGGAGAGAUAAAGAAUG</td>\n",
       "      <td>-2.212657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.212657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AACAUUCGGAGAGAAAAUAUAUG</td>\n",
       "      <td>-2.151750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.151750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AGAAUUUGGGAGGAUAUAUGAUG</td>\n",
       "      <td>-2.246053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.246053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AUGCCAAAAGGAAAACAGGUAUG</td>\n",
       "      <td>-1.482294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.482294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AAUGGAACGGGAGGAAUAACAUG</td>\n",
       "      <td>-2.064702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.064702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ACUCGAAAGGAGGUAAGAAUAUG</td>\n",
       "      <td>-1.805792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.805792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UUAACAAGAGGAAGAGAGAGAUG</td>\n",
       "      <td>-1.783351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.783351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AUGACAAAAGGAGAAAAAAGAUG</td>\n",
       "      <td>-1.849757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.849757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UGUUGAAAGAGGAGGAAAUGAUG</td>\n",
       "      <td>-1.834831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.834831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AAUGUAACGGGUAAAAAAAGAUG</td>\n",
       "      <td>-1.809042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.809042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AUACAGACGAGGAGGAUGUAAUG</td>\n",
       "      <td>-1.876679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.876679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        seq      pred  actual      diff\n",
       "0   UGAAUUAGGAGGGUAUAGAAAUG -2.018470     0.0 -2.018470\n",
       "1   GUACGAAGAGGAGGAAUAUAAUG -2.104053     0.0 -2.104053\n",
       "2   AGAAGAGGAGGACUGAGAUGAUG -2.026808     0.0 -2.026808\n",
       "3   UUGGAGAAUAGGAGGAAAAGAUG -1.472379     0.0 -1.472379\n",
       "4   ACGAGAAGAGGAGGAGAAAAAUG -1.884343     0.0 -1.884343\n",
       "5   AUAGAAGCGGAGGAAUAAUCAUG -1.577263     0.0 -1.577263\n",
       "6   GUGAGUAGAGGAGAUAUAUAAUG -1.920333     0.0 -1.920333\n",
       "7   AGAGAGAGGAGAGAGAAAAAAUG -1.835910     0.0 -1.835910\n",
       "8   AUACGAGAGAGGAUAAUGAGAUG -1.957115     0.0 -1.957115\n",
       "9   AAACUGAGGAGAGAUAAAGAAUG -2.212657     0.0 -2.212657\n",
       "10  AACAUUCGGAGAGAAAAUAUAUG -2.151750     0.0 -2.151750\n",
       "11  AGAAUUUGGGAGGAUAUAUGAUG -2.246053     0.0 -2.246053\n",
       "12  AUGCCAAAAGGAAAACAGGUAUG -1.482294     0.0 -1.482294\n",
       "13  AAUGGAACGGGAGGAAUAACAUG -2.064702     0.0 -2.064702\n",
       "14  ACUCGAAAGGAGGUAAGAAUAUG -1.805792     0.0 -1.805792\n",
       "15  UUAACAAGAGGAAGAGAGAGAUG -1.783351     0.0 -1.783351\n",
       "16  AUGACAAAAGGAGAAAAAAGAUG -1.849757     0.0 -1.849757\n",
       "17  UGUUGAAAGAGGAGGAAAUGAUG -1.834831     0.0 -1.834831\n",
       "18  AAUGUAACGGGUAAAAAAAGAUG -1.809042     0.0 -1.809042\n",
       "19  AUACAGACGAGGAGGAUGUAAUG -1.876679     0.0 -1.876679"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "549f1fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>UGUUGAAGUCCCUGUUACGUAUG</td>\n",
       "      <td>-1.334727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.334727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>UUCUAUAUGGGACUAAACGAAUG</td>\n",
       "      <td>-2.040472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.040472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>AACCCAUAGGGGCACUAAACAUG</td>\n",
       "      <td>-2.178013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.178013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>AAGCAUGUAUAGGUAAAGAAAUG</td>\n",
       "      <td>-1.467031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.467031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>AAUGAAAGGGAAAGAAAGAGAUG</td>\n",
       "      <td>-1.598732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.598732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>AGAUAGACUGGAAGAACAUGAUG</td>\n",
       "      <td>-1.755444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.755444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>AUAUGCUAUGAGCGGUGGUUAUG</td>\n",
       "      <td>-1.351755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.351755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>CAGUAUAAAGGAAUAAAAAGAUG</td>\n",
       "      <td>-1.670071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.670071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>GAUAAAAGGUGAUUCUUAGUAUG</td>\n",
       "      <td>-1.551362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.551362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>GUGAAGAGGUAUAGAGAAGGAUG</td>\n",
       "      <td>-1.151022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.151022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>UAAUCAGAAUAAGUAGAAUAAUG</td>\n",
       "      <td>-1.164137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.164137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>UAUUCAAUUAGAAAGAGAACAUG</td>\n",
       "      <td>-1.287960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.287960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>AAGGCAAUAUGGUCAACUCUAUG</td>\n",
       "      <td>-1.705464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.705464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>AUGCUGGGGAAAAAAGAGAAAUG</td>\n",
       "      <td>-1.031119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.031119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>UUCAAGCCACAGGAGCAUGAAUG</td>\n",
       "      <td>-1.435364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.435364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>UUAACGUUUUGGACACACCUAUG</td>\n",
       "      <td>-1.575707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.575707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>ACGGAUGAGGAAUGACGGUCAUG</td>\n",
       "      <td>-1.312556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.312556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>ACGGUAAAAGAGUACAACUAAUG</td>\n",
       "      <td>-1.562825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.562825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>AUAGAACUCGAGGCACAACCAUG</td>\n",
       "      <td>-1.849448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.849448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>UACUCACAGAGAGUAAUGAUAUG</td>\n",
       "      <td>-1.809855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.809855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seq      pred  actual      diff\n",
       "2319  UGUUGAAGUCCCUGUUACGUAUG -1.334727     0.0 -1.334727\n",
       "2320  UUCUAUAUGGGACUAAACGAAUG -2.040472     0.0 -2.040472\n",
       "2321  AACCCAUAGGGGCACUAAACAUG -2.178013     1.0 -3.178013\n",
       "2322  AAGCAUGUAUAGGUAAAGAAAUG -1.467031     1.0 -2.467031\n",
       "2323  AAUGAAAGGGAAAGAAAGAGAUG -1.598732     1.0 -2.598732\n",
       "2324  AGAUAGACUGGAAGAACAUGAUG -1.755444     1.0 -2.755444\n",
       "2325  AUAUGCUAUGAGCGGUGGUUAUG -1.351755     1.0 -2.351755\n",
       "2326  CAGUAUAAAGGAAUAAAAAGAUG -1.670071     1.0 -2.670071\n",
       "2327  GAUAAAAGGUGAUUCUUAGUAUG -1.551362     1.0 -2.551362\n",
       "2328  GUGAAGAGGUAUAGAGAAGGAUG -1.151022     1.0 -2.151022\n",
       "2329  UAAUCAGAAUAAGUAGAAUAAUG -1.164137     1.0 -2.164137\n",
       "2330  UAUUCAAUUAGAAAGAGAACAUG -1.287960     1.0 -2.287960\n",
       "2331  AAGGCAAUAUGGUCAACUCUAUG -1.705464     0.0 -1.705464\n",
       "2332  AUGCUGGGGAAAAAAGAGAAAUG -1.031119     0.0 -1.031119\n",
       "2333  UUCAAGCCACAGGAGCAUGAAUG -1.435364     0.0 -1.435364\n",
       "2334  UUAACGUUUUGGACACACCUAUG -1.575707     0.0 -1.575707\n",
       "2335  ACGGAUGAGGAAUGACGGUCAUG -1.312556     0.0 -1.312556\n",
       "2336  ACGGUAAAAGAGUACAACUAAUG -1.562825     0.0 -1.562825\n",
       "2337  AUAGAACUCGAGGCACAACCAUG -1.849448     0.0 -1.849448\n",
       "2338  UACUCACAGAGAGUAAUGAUAUG -1.809855     0.0 -1.809855"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496018a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
